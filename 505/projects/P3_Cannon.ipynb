{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "with open('/home/thomas/git/datascience/MSDataSci/505/data/project_three/ids.txt') as id_file:\n",
    "    for line in id_file:\n",
    "        line = line.replace('.txt\\n','')\n",
    "        ids.append(line)\n",
    "\n",
    "iqs = []\n",
    "iqs_labels = []\n",
    "iqs_binary_labels = []\n",
    "iqs_ternary_labels = []\n",
    "matrices = []\n",
    "vectors = []\n",
    "data_dict = {}\n",
    "i = 0\n",
    "for id in ids:\n",
    "    data_dict[id] = {}\n",
    "    with open('/home/thomas/git/datascience/MSDataSci/505/data/project_three/dataset/{}.txt'.format(id)) as iq_file:\n",
    "        iq = float(iq_file.readline().replace('\\n',''))\n",
    "        iqs.append(np.array([iq]))\n",
    "        iqs_labels.append([iq,int(0 if iq<100 else 1),str('above average' if iq>110 else ('below average' if iq<90 else 'average'))])\n",
    "        iqs_binary_labels.append(0 if iq<100 else 1)\n",
    "        iqs_ternary_labels.append(2 if iq>110 else (0 if iq<90 else 1))\n",
    "        data_dict[id]['iq'] = [iq,int(0 if iq<100 else 1),str('above average' if iq>110 else ('below average' if iq<90 else 'average'))]\n",
    "    \n",
    "    matrix = np.genfromtxt('/home/thomas/git/datascience/MSDataSci/505/data/project_three/dataset/{}.csv'.format(id),delimiter=',') \n",
    "    vector = np.array([np.array(np.genfromtxt('/home/thomas/git/datascience/MSDataSci/505/data/project_three/dataset/{}_vec.csv'.format(id),delimiter=','))])\n",
    "\n",
    "    matrices.append(matrix)\n",
    "    vectors.append(vector[0])\n",
    "\n",
    "    data_dict[id]['pid'] = i\n",
    "    data_dict[id]['matrix'] = matrix\n",
    "    data_dict[id]['vector'] = vector\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "iqs_binary_labels = np.array(iqs_binary_labels)\n",
    "    \n",
    "matrices = np.array(matrices)\n",
    "vects = np.array(vectors)\n",
    "iqs = np.array(iqs)\n",
    "iqs_binary_labels = np.array(iqs_binary_labels)\n",
    "iqs_ternary_labels = np.array(iqs_ternary_labels)\n",
    "regions = list(csv.reader(open(\"/home/thomas/git/datascience/MSDataSci/505/data/project_three/Atlas_regions.csv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_log_dist = exp(mu+((sigma**2)/2))\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(vects)\n",
    "vectors = pca.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0. 0. 0.]\n",
      "recall: [0. 0. 0.]\n",
      "fscore: [0. 0. 0.]\n",
      "support: [ 8 30  0]\n",
      "Fold Score: 0.95\n",
      "-----------------------\n",
      "precision: [0. 0. 0.]\n",
      "recall: [0. 0. 0.]\n",
      "fscore: [0. 0. 0.]\n",
      "support: [ 7 32  0]\n",
      "Fold Score: 1.00\n",
      "-----------------------\n",
      "precision: [0. 0. 0.]\n",
      "recall: [0. 0. 0.]\n",
      "fscore: [0. 0. 0.]\n",
      "support: [ 7 32  0]\n",
      "Fold Score: 0.95\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/thomas/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/thomas/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/thomas/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/thomas/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/thomas/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "bin_pipeline = Pipeline([('feature_selection',PCA()),\n",
    "                     ('scaling',StandardScaler()),\n",
    "                     ('classifier',LogisticRegression(multi_class='auto',solver='liblinear'))])\n",
    "\n",
    "kf = KFold(n_splits=3,shuffle=True)\n",
    "kf.get_n_splits(vectors)\n",
    "\n",
    "for test_idx, train_idx in kf.split(vectors):\n",
    "    vectors_train, vectors_test = vectors[train_idx], vectors[test_idx]\n",
    "    iqs_binary_labels_train, iqs_binary_labels_test = iqs_binary_labels[train_idx], iqs_binary_labels[test_idx]\n",
    "\n",
    "    bin_pipeline.fit(vectors_train,iqs_binary_labels_train)\n",
    "    score = bin_pipeline.score(vectors_train,iqs_binary_labels_train)\n",
    "    bin_scores.append(score)\n",
    "    Yhat = pipeline.predict(vectors_test)\n",
    "    metrics = precision_recall_fscore_support(iqs_binary_labels_test,Yhat)\n",
    "    print('precision: {}'.format(str(metrics[0])))\n",
    "    print('recall: {}'.format(str(metrics[1])))\n",
    "    print('fscore: {}'.format(str(metrics[2])))\n",
    "    print('support: {}'.format(str(metrics[3])))\n",
    "    print('Fold Score: {0:0.2f}'.format(score))\n",
    "    print('-----------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.        0.        0.5862069]\n",
      "recall: [0. 0. 1.]\n",
      "fscore: [0.         0.         0.73913043]\n",
      "support: [ 2 10 17]\n",
      "Fold Score: 0.76\n",
      "precision: [0.         0.         0.55172414]\n",
      "recall: [0. 0. 1.]\n",
      "fscore: [0.         0.         0.71111111]\n",
      "support: [ 4  9 16]\n",
      "Fold Score: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/thomas/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "ter_pipeline = Pipeline([('feature_selection',PCA()),\n",
    "                         ('scaling',StandardScaler()),\n",
    "                         ('classifier',SVC())])\n",
    "\n",
    "kf = KFold(n_splits=2,shuffle=True)\n",
    "kf.get_n_splits(vectors)\n",
    "\n",
    "for test_idx, train_idx in kf.split(vectors):\n",
    "    vectors_train, vectors_test = vectors[train_idx], vectors[test_idx]\n",
    "    iqs_ternary_labels_train, iqs_ternary_labels_test = iqs_ternary_labels[train_idx], iqs_ternary_labels[test_idx]\n",
    "\n",
    "    ter_pipeline.fit(vectors_train,iqs_ternary_labels_train)\n",
    "    score = ter_pipeline.score(vectors_train,iqs_ternary_labels_train)\n",
    "    bin_scores.append(score)\n",
    "    Yhat = pipeline.predict(vectors_test)\n",
    "    metrics = precision_recall_fscore_support(iqs_ternary_labels_test,Yhat)\n",
    "    print('precision: {}'.format(str(metrics[0])))\n",
    "    print('recall: {}'.format(str(metrics[1])))\n",
    "    print('fscore: {}'.format(str(metrics[2])))\n",
    "    print('support: {}'.format(str(metrics[3])))\n",
    "    print('Fold Score: {0:0.2f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 228.556\n",
      "MAE: 12.190\n",
      "R: -0.369\n",
      "Explained Variance: 0.136\n",
      "================\n",
      "MSE: 235.721\n",
      "MAE: 13.071\n",
      "R: 0.182\n",
      "Explained Variance: 0.033\n",
      "================\n",
      "MSE: 154.373\n",
      "MAE: 9.742\n",
      "R: 0.364\n",
      "Explained Variance: 0.132\n",
      "================\n",
      "MSE: 270.153\n",
      "MAE: 13.348\n",
      "R: -0.387\n",
      "Explained Variance: 0.150\n",
      "================\n",
      "MSE: 320.123\n",
      "MAE: 16.010\n",
      "R: 0.003\n",
      "Explained Variance: 0.000\n",
      "================\n",
      "MSE: 128.637\n",
      "MAE: 9.787\n",
      "R: -0.419\n",
      "Explained Variance: 0.175\n",
      "================\n",
      "MSE: 93.586\n",
      "MAE: 7.947\n",
      "R: -0.550\n",
      "Explained Variance: 0.303\n",
      "================\n",
      "\n",
      "Fold R-squared scores mean: 0.1328103169754102 and stdev: 0.09141644546028044\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lin_reg_scores = []\n",
    "kf = KFold(n_splits=7,shuffle=True)\n",
    "for train_index, test_index in kf.split(vectors,iqs):\n",
    "\n",
    "    vectors_train, vectors_test = vectors[train_index], vectors[test_index]\n",
    "    iqs_train, iqs_test = iqs[train_index], iqs[test_index]\n",
    "\n",
    "    linreg = linear_model.LinearRegression()\n",
    "    linreg.fit(vectors_train,iqs_train)\n",
    "    Yhat = linreg.predict(vectors_test)\n",
    "\n",
    "    # plt.hist(vectors[:,0],bins=10)\n",
    "    # plt.hist(new_columns[8],bins=10)\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.boxplot(vectors[:,0:50])\n",
    "\n",
    "    # plt.boxplot(vectors[:,51:100])\n",
    "    # plt.show()\n",
    "    R_val = (pearsonr(iqs_test, Yhat)[0])\n",
    "    MSE = mean_squared_error(iqs_test, Yhat)\n",
    "    MAE = mean_absolute_error(iqs_test, Yhat)\n",
    "    print('MSE: {0:0.3f}'.format(MSE))\n",
    "    print('MAE: {0:0.3f}'.format(MAE))\n",
    "    print('R: {0:0.3f}'.format(float(R_val)))\n",
    "    print('Explained Variance: {0:0.3f}'.format(float(R_val)**2))\n",
    "    print('================')\n",
    "    \n",
    "    lin_reg_scores.append(R_val[0]**2)\n",
    "print('\\nFold R-squared scores mean: {} and stdev: {}'.format(np.mean(lin_reg_scores),np.std(lin_reg_scores)))    \n",
    "\n",
    "# plt.hist(scores,bins=6)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
